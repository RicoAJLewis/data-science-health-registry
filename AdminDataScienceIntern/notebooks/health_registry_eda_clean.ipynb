{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b161434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../health_registry.csv\")\n",
    "\n",
    "# Basic info\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d37b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.replace('_', ' ').title() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b478e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aac61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Capacity\": \"Bed Capacity\"}, inplace=True)\n",
    "# remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75de890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the Facility Id\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_facility_id(fid):\n",
    "    if pd.isna(fid):\n",
    "        return None\n",
    "    fid = str(fid).strip()\n",
    "    fid = re.sub(r\"[^\\d]\", \"\", fid)  # remove non-numeric\n",
    "    if fid.isdigit():\n",
    "        return f\"HF-{int(fid):04d}\"\n",
    "    return fid  # fallback\n",
    "\n",
    "df[\"Facility Id\"] = df[\"Facility Id\"].apply(clean_facility_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df.duplicated(subset=[\n",
    "    \"Facility Id\", \"Facility Name\", \"Region\", \"Inspection Date\"\n",
    "], keep=False)]\n",
    "\n",
    "display(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping Duplicates again.\n",
    "df.drop_duplicates(subset=[\n",
    "    \"Facility Id\", \"Facility Name\", \"Region\", \"Inspection Date\"\n",
    "], keep='first', inplace=True)\n",
    "display(df.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract numeric digits from Facility Id (e.g., \"HF-0003\" → 3)\n",
    "df['Facility Id Num'] = df['Facility Id'].str.extract(r'(\\d+)').astype(float)\n",
    "df.sort_values(by='Facility Id Num', inplace=True, na_position='last')\n",
    "df.drop(columns='Facility Id Num', inplace=True)\n",
    "\n",
    "#df.sort_values(by='Facility Id', ascending=True, inplace=True)\n",
    "#df.sort_values(by='Facility Id', na_position='last', inplace=True)\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6fc005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning up facility names \n",
    "# Define abbreviation replacements used inside the cleaning function\n",
    "replacements = {\n",
    "    r\"\\bHosp\\.?\\b\": \"Hospital\",\n",
    "    r\"\\bHlth Ctr\\.?\\b\": \"Health Center\",\n",
    "    r\"\\bCtr\\.?\\b\": \"Center\",\n",
    "    r\"\\bMed\\.?\\b\": \"Medical\",\n",
    "    r\"\\bPLC\\b\": \"\"\n",
    "}\n",
    "\n",
    "def clean_and_expand_facility_name(name):\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    # Remove (parenthetical)\n",
    "    name = re.sub(r\"\\s*\\([^)]*\\)\", \"\", name)\n",
    "    # Remove emojis and unwanted characters\n",
    "    name = re.sub(r\"[^\\w\\s.,'-]\", \"\", name)\n",
    "    # Replace common abbreviations\n",
    "    for pattern, replacement in replacements.items():\n",
    "        name = re.sub(pattern, replacement, name, flags=re.IGNORECASE)\n",
    "    # Remove trailing punctuation like dots or spaces\n",
    "    name = re.sub(r\"[.,;:\\s]+$\", \"\", name)\n",
    "    return name.strip()\n",
    "\n",
    "df[\"Facility Name\"] = df[\"Facility Name\"].apply(clean_and_expand_facility_name)\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa139962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove emojis from any string\n",
    "def remove_emojis(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return re.sub(r\"[^\\w\\s.,'-]\", \"\", str(text))\n",
    "\n",
    "# Apply to Facility Type\n",
    "df[\"Facility Type\"] = df[\"Facility Type\"].apply(remove_emojis)\n",
    "\n",
    "# Apply to Remarks, then fill blanks or NaNs with \"-\"\n",
    "df[\"Remarks\"] = df[\"Remarks\"].apply(remove_emojis)\n",
    "df[\"Remarks\"] = df[\"Remarks\"].fillna(\"-\")\n",
    "df[\"Remarks\"] = df[\"Remarks\"].replace(\"\", \"-\")  # in case some are blank strings\n",
    "\n",
    "# Map known messy labels to standardized values\n",
    "facility_type_map = {\n",
    "    r\"\\bCHC\\b\": \"Community Health Center\",\n",
    "    r\"Community Health Ctr\\.?\": \"Community Health Center\",\n",
    "    r\"Community Health Centre\": \"Community Health Center\",\n",
    "    r\"Health Ctr\\.?\": \"Health Center\",\n",
    "    r\"Health Centre\": \"Health Center\",\n",
    "    r\"Polyclinic\": \"Polyclinic\",\n",
    "    r\"Hospital\\.?\": \"Hospital\",\n",
    "    r\"Hosp\\.?\": \"Hospital\",\n",
    "    r\"Clinic\": \"Clinic\",\n",
    "    r\"Clnc\": \"Clinic\",\n",
    "}\n",
    "\n",
    "def normalize_facility_type(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    value = re.sub(r\"[^\\w\\s.,'-]\", \"\", str(value))  # remove emojis\n",
    "    for pattern, replacement in facility_type_map.items():\n",
    "        value = re.sub(pattern, replacement, value, flags=re.IGNORECASE)\n",
    "    return value.strip().title()\n",
    "\n",
    "df[\"Facility Type\"] = df[\"Facility Type\"].apply(normalize_facility_type)\n",
    "\n",
    "df[[\"Facility Type\", \"Remarks\"]].drop_duplicates().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f94c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Facility Type\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a544384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map specific incorrect or overly granular labels to final categories\n",
    "final_facility_type_map = {\n",
    "    \"Health Center\": \"Community Health Center\",\n",
    "    \"Clinic\": \"Polyclinic\",\n",
    "    \"Hospitalital\": \"Hospital\"\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df[\"Facility Type\"] = df[\"Facility Type\"].replace(final_facility_type_map)\n",
    "df[\"Facility Type\"].value_counts()\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb32036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the Bed Capacity column\n",
    "# Map common word numbers to digits\n",
    "word_to_num = {\n",
    "    \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5,\n",
    "    \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10,\n",
    "    \"eleven\": 11, \"twelve\": 12, \"thirteen\": 13, \"fourteen\": 14,\n",
    "    \"fifteen\": 15, \"sixteen\": 16, \"seventeen\": 17, \"eighteen\": 18,\n",
    "    \"nineteen\": 19, \"twenty\": 20\n",
    "}\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_bed_capacity(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    value = str(value).strip().lower()\n",
    "\n",
    "    # Replace word numbers with digits\n",
    "    for word, num in word_to_num.items():\n",
    "        if word in value:\n",
    "            return num\n",
    "\n",
    "    # Extract numeric portion from strings like \"156 bed\", \"488\"\n",
    "    match = re.search(r'\\d+', value)\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "# Apply the cleaning function\n",
    "df[\"Bed Capacity\"] = df[\"Bed Capacity\"].apply(clean_bed_capacity).astype(\"Int64\")\n",
    "df[\"Bed Capacity\"].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebbc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Bed Capacity\"].isna()][[\"Facility Name\", \"Bed Capacity\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f592688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Licence Issue Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab43ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the region column\n",
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# ✅ Official Barbados parishes (target output format)\n",
    "valid_parishes = [\n",
    "    \"Christ Church\", \"St. Andrew\", \"St. George\", \"St. James\", \"St. John\",\n",
    "    \"St. Joseph\", \"St. Lucy\", \"St. Michael\", \"St. Peter\", \"St. Philip\", \"St. Thomas\"\n",
    "]\n",
    "\n",
    "# 🛠️ Manual correction map (lowercased)\n",
    "manual_corrections = {\n",
    "    \"stjoseph\": \"St. Joseph\",\n",
    "    \"stjohn\": \"St. John\",\n",
    "    \"stjames\": \"St. James\",\n",
    "    \"stmichael\": \"St. Michael\",\n",
    "    \"stlucy\": \"St. Lucy\",\n",
    "    \"stgeorge\": \"St. George\",\n",
    "    \"standrew\": \"St. Andrew\",\n",
    "    \"stpeter\": \"St. Peter\",\n",
    "    \"retep ts\": \"St. Peter\",\n",
    "    \"nhoj ts\": \"St. John\",\n",
    "    \"ycul ts\": \"St. Lucy\",\n",
    "    \"hcruhc tsirhc\": \"Christ Church\",\n",
    "    \"werdna ts\": \"St. Andrew\",\n",
    "    \"egroeg ts\": \"St. George\",\n",
    "    \"hpesoj ts\": \"St. Joseph\",\n",
    "    \"leahcim ts\": \"St. Michael\",\n",
    "    \"semaj ts\": \"St. James\"\n",
    "}\n",
    "\n",
    "# 🧼 Main cleaning function\n",
    "def clean_region(value):\n",
    "    if not pd.notna(value):\n",
    "        return None\n",
    "\n",
    "    val = str(value).strip().lower()\n",
    "    val = re.sub(r\"[^\\w\\s]\", \"\", val)         # remove punctuation\n",
    "    val = val.replace(\"parish\", \"\").strip()   # remove \"parish\" word\n",
    "\n",
    "    # Manual fix if matched\n",
    "    if val in manual_corrections:\n",
    "        return manual_corrections[val]\n",
    "\n",
    "    # Fix glued \"stlucy\" → \"St. Lucy\"\n",
    "    if val.startswith(\"st\") and len(val) > 2:\n",
    "        for parish in valid_parishes:\n",
    "            if parish.lower().replace(\".\", \"\").replace(\" \", \"\") == val:\n",
    "                return parish\n",
    "\n",
    "    # Fuzzy fallback match\n",
    "    result = process.extractOne(val, valid_parishes, scorer=fuzz.token_sort_ratio)\n",
    "    if result and result[1] >= 85:\n",
    "        return result[0]\n",
    "\n",
    "    return None  # force null if no good match\n",
    "\n",
    "# ✅ Apply correction\n",
    "df[\"Region\"] = df[\"Region\"].apply(clean_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bca884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Region\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc885848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧼 Clean + Normalize Licence Issue Date\n",
    "df[\"Licence Issue Date\"] = pd.to_datetime(df[\"Licence Issue Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# Format to 'DD-MM-YYYY' string\n",
    "df[\"Licence Issue Date\"] = df[\"Licence Issue Date\"].dt.strftime('%d-%m-%Y')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b79093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧼 Clean + Normalize Inspection Date\n",
    "df[\"Inspection Date\"] = pd.to_datetime(df[\"Inspection Date\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# Format to 'DD-MM-YYYY' string (only if date parsing succeeded)\n",
    "df[\"Inspection Date\"] = df[\"Inspection Date\"].dt.strftime('%d-%m-%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Inspection Date\"].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa839f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def clean_gps(gps):\n",
    "    if not pd.notna(gps):\n",
    "        return np.nan\n",
    "\n",
    "    # Remove brackets, emojis, and extra characters\n",
    "    gps = re.sub(r\"[^\\d.,\\s\\-]\", \"\", gps)\n",
    "    \n",
    "    # Split by comma or space\n",
    "    parts = re.split(r\"[,\\s]+\", gps.strip())\n",
    "    \n",
    "    # Filter out empty strings\n",
    "    parts = [p for p in parts if p]\n",
    "\n",
    "    # Expect exactly 2 parts (lat, lon)\n",
    "    if len(parts) != 2:\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        lat = round(float(parts[0]), 5)\n",
    "        lon = round(float(parts[1]), 5)\n",
    "        return f\"{lat}, {lon}\"\n",
    "    except:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49872c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gps Location\"] = df[\"Gps Location\"].apply(clean_gps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13872a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gps Location\"].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ccc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873651e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove newline characters and the literal string \"NewLine\"\n",
    "df[\"Facility Name\"] = df[\"Facility Name\"].str.replace(r\"\\n\", \" \", regex=True)\n",
    "df[\"Facility Name\"] = df[\"Facility Name\"].str.replace(r\"NewLine\", \" \", regex=True)\n",
    "\n",
    "# Optional: remove extra spaces\n",
    "df[\"Facility Name\"] = df[\"Facility Name\"].str.strip().replace(r\"\\s+\", \" \", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Facility Name\"].head(10)\n",
    "df[\"Facility Name\"].str.contains(\"NewLine|\\n\", regex=True).sum()  # Should return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Facility Type\"] = df[\"Facility Type\"].fillna(\"-\")\n",
    "\n",
    "# Also handle empty strings or whitespace-only entries\n",
    "df[\"Facility Type\"] = df[\"Facility Type\"].replace(r\"^\\s*$\", \"-\", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f58da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Facility Type\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Bed Capacity\"] = df[\"Bed Capacity\"].fillna(0)\n",
    "df[\"Bed Capacity\"] = df[\"Bed Capacity\"].replace(r\"^\\s*$\", 0, regex=True)\n",
    "\n",
    "# Convert to integer (or float if needed)\n",
    "df[\"Bed Capacity\"] = pd.to_numeric(df[\"Bed Capacity\"], errors=\"coerce\").fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Bed Capacity\"].value_counts(dropna=False).head()\n",
    "df[\"Bed Capacity\"].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19274f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace actual None or NaN\n",
    "df[\"Region\"] = df[\"Region\"].fillna(\"-\")\n",
    "\n",
    "# Replace the string \"None\" (in case it was typed as text)\n",
    "df[\"Region\"] = df[\"Region\"].replace(\"None\", \"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268baeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Region\"] = df[\"Region\"].replace(r\"^\\s*$\", \"-\", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35367509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Region\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a776f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace actual NaN/None\n",
    "df[\"Gps Location\"] = df[\"Gps Location\"].fillna(\"-\")\n",
    "\n",
    "# Also handle empty strings or whitespace-only entries\n",
    "df[\"Gps Location\"] = df[\"Gps Location\"].replace(r\"^\\s*$\", \"-\", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gps Location\"].value_counts(dropna=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3eaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Remarks\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace actual NaN values\n",
    "df[\"Remarks\"] = df[\"Remarks\"].fillna(\"-\")\n",
    "\n",
    "# Replace strings that are just spaces or empty\n",
    "df[\"Remarks\"] = df[\"Remarks\"].replace(r\"^\\s*$\", \"-\", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Remarks\"].value_counts(dropna=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56372e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df[\"Facility Id\"] = df.index.map(lambda x: f\"HF-{str(x).zfill(6)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is Facility Id unique?\", df[\"Facility Id\"].is_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750997a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both columns are datetime just in case\n",
    "df[\"Licence Issue Date\"] = pd.to_datetime(df[\"Licence Issue Date\"], dayfirst=True, errors='coerce')\n",
    "df[\"Inspection Date\"] = pd.to_datetime(df[\"Inspection Date\"], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Find rows where inspection date is earlier than license issue date\n",
    "mask = df[\"Inspection Date\"] < df[\"Licence Issue Date\"]\n",
    "\n",
    "# Swap values where the mask is True\n",
    "df.loc[mask, [\"Licence Issue Date\", \"Inspection Date\"]] = df.loc[mask, [\"Inspection Date\", \"Licence Issue Date\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fabf582",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"Inspection Date\"] < df[\"Licence Issue Date\"]).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6214df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e56911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_health_registry.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"cleaned_health_registry.csv\")\n",
    "\n",
    "# ---------- 1. Check for missing values ----------\n",
    "print(\"🧼 Missing Values Summary:\")\n",
    "print(df.isna().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# ---------- 2. Validate Bed Capacity ----------\n",
    "print(\"🚫 Invalid Bed Capacities (negative or non-integer):\")\n",
    "print(df[~df[\"Bed Capacity\"].apply(lambda x: isinstance(x, (int, float)) and x >= 0)])\n",
    "print(\"\\n\")\n",
    "\n",
    "# ---------- 3. Validate Gps Location Format ----------\n",
    "pattern = r\"^-?\\d+\\.\\d+,\\s*-?\\d+\\.\\d+$\"\n",
    "invalid_gps = df[~df[\"Gps Location\"].astype(str).str.match(pattern)]\n",
    "print(\"🌍 Invalid GPS Format Entries:\")\n",
    "print(invalid_gps)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ---------- 4. Validate Categorical Fields ----------\n",
    "print(\"📌 Unique Facility Types:\")\n",
    "print(df[\"Facility Type\"].unique())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"📌 Unique Remarks:\")\n",
    "print(df[\"Remarks\"].unique())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"📌 Unique Regions:\")\n",
    "print(df[\"Region\"].unique())\n",
    "print(\"\\n\")\n",
    "\n",
    "# ---------- 5. Date Validation: Inspection must be >= Licence ----------\n",
    "df[\"Licence Issue Date\"] = pd.to_datetime(df[\"Licence Issue Date\"], dayfirst=True, errors='coerce')\n",
    "df[\"Inspection Date\"] = pd.to_datetime(df[\"Inspection Date\"], dayfirst=True, errors='coerce')\n",
    "\n",
    "out_of_order = df[df[\"Inspection Date\"] < df[\"Licence Issue Date\"]]\n",
    "print(\"📅 Entries Where Inspection Date Is Before Licence Issue Date:\")\n",
    "print(out_of_order)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ---------- 6. Capitalization Standardization ----------\n",
    "df[\"Facility Name\"] = df[\"Facility Name\"].str.title()\n",
    "df[\"Region\"] = df[\"Region\"].str.title()\n",
    "\n",
    "# ---------- 7. Whitespace Cleanup ----------\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# ---------- 8. Facility Id Uniqueness ----------\n",
    "is_unique = df[\"Facility Id\"].is_unique\n",
    "print(f\"🔍 Is Facility Id Unique? {is_unique}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# ---------- Optional: Save validated version ----------\n",
    "df.to_csv(\"validated_health_registry.csv\", index=False)\n",
    "print(\"✅ Cleaned and validated file saved as 'validated_health_registry.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca257f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keyword-based corrections\n",
    "def correct_facility_type(row):\n",
    "    name = str(row[\"Facility Name\"]).lower()\n",
    "\n",
    "    if \"polyclinic\" in name:\n",
    "        return \"Polyclinic\"\n",
    "    elif \"clinic\" in name:\n",
    "        return \"Polyclinic\"  # unify all clinic types\n",
    "    elif \"health center\" in name:\n",
    "        return \"Community Health Center\"\n",
    "    elif \"center\" in name:\n",
    "        return \"Community Health Center\"\n",
    "    elif \"hospital\" in name:\n",
    "        return \"Hospital\"\n",
    "    else:\n",
    "        return row[\"Facility Type\"]  # keep original if no clue\n",
    "\n",
    "# Apply corrections\n",
    "df[\"Facility Type\"] = df.apply(correct_facility_type, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0136e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ed83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Facility Type\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cba8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the cleaned data\n",
    "df = pd.read_csv(\"cleaned_health_registry.csv\")\n",
    "\n",
    "# 2. Treat blanks and dashes as missing\n",
    "df.replace(['', ' ', '-'], pd.NA, inplace=True)\n",
    "\n",
    "# 3. Identify rows with any missing data\n",
    "missing_data_df = df[df.isna().any(axis=1)]\n",
    "\n",
    "# 4. Save rows with missing data\n",
    "missing_data_df.to_csv(\"missing_data.csv\", index=False)\n",
    "\n",
    "# 5. Remove rows with missing data from the main DataFrame\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# 6. Save the updated cleaned dataset\n",
    "df_cleaned.to_csv(\"cleaned_health_registry.csv\", index=False)\n",
    "\n",
    "print(f\"✅ {len(missing_data_df)} rows with missing data exported to 'missing_data.csv'.\")\n",
    "print(f\"✅ Cleaned dataset saved with {len(df_cleaned)} records.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cleaned_health_registry.csv\")\n",
    "df.shape\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8449d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Facility Type\"].unique()\n",
    "df[\"Region\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df == '-').sum()\n",
    "(df == '').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f11fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure  columns are in correct data type format\n",
    "df[\"Licence Issue Date\"] = pd.to_datetime(df[\"Licence Issue Date\"], errors=\"coerce\", dayfirst=True)\n",
    "df[\"Inspection Date\"] = pd.to_datetime(df[\"Inspection Date\"], errors=\"coerce\", dayfirst=True)\n",
    "df[\"Facility Type\"] = df[\"Facility Type\"].astype(\"category\")\n",
    "df[\"Region\"] = df[\"Region\"].astype(\"category\")\n",
    "df[\"Remarks\"] = df[\"Remarks\"].astype(\"category\")\n",
    "df[['Latitude', 'Longitude']] = df['Gps Location'].str.split(', ', expand=True).astype(float)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Facility Id\"] = df[\"Facility Id\"].astype(\"string\")\n",
    "df[\"Facility Name\"] = df[\"Facility Name\"].astype(\"string\")\n",
    "df.drop(columns=[\"Gps Location\"], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a18afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')  # Full summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da32e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ydata-profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f323e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Create the profile\n",
    "profile = ProfileReport(df, title=\"Health Registry Dataset Profile\", explorative=True)\n",
    "\n",
    "# Save to HTML\n",
    "profile.to_file(\"health_registry_profile.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51603d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
